{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb1a0b6",
   "metadata": {},
   "source": [
    "# Práctica clasificación Smartports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063e66c5",
   "metadata": {},
   "source": [
    "### Antonio Serrano Rodriguez, Guillermo García Engelmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50626ab9",
   "metadata": {},
   "source": [
    "## Transformaciones de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd3d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DatasetReader\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Estadísticas de ImageNet para normalizar\n",
    "imagenet_mean = (0.485, 0.456, 0.406)\n",
    "imagenet_std  = (0.229, 0.224, 0.225)\n",
    "\n",
    "# Transformaciones “base” (redimensionar y normalizar)  \n",
    "regnettransforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                   \n",
    "    transforms.ToTensor(),                           \n",
    "    transforms.Normalize(imagenet_mean, imagenet_std) \n",
    "])\n",
    "\n",
    "# Transformaciones para data augmentation \n",
    "aug_transforms = transforms.Compose([\n",
    "    # Varias escalas y recortes aleatorios según proporciones reales del dataset \n",
    "    transforms.RandomResizedCrop(\n",
    "        224,\n",
    "        scale=(0.7, 1.0),    # barcos muy lejos (70%) o casi completos (100%)\n",
    "        ratio=(0.8, 1.2)     # relación de aspecto ligeramente variable\n",
    "    ),\n",
    "\n",
    "    # Ángulos y perspectiva \n",
    "    transforms.RandomRotation(15),                   \n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),          \n",
    "\n",
    "    # Iluminación y color (amaneceres, atardeceres, sombras…) \n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.5,\n",
    "        contrast=0.5,\n",
    "        saturation=0.3,\n",
    "        hue=0.1\n",
    "    ),\n",
    "\n",
    "    # Simular desenfoque típico de las cámaras\n",
    "    transforms.RandomApply(\n",
    "        [transforms.GaussianBlur(kernel_size=3)],\n",
    "        p=0.3\n",
    "    ),\n",
    "\n",
    "    # Aplastamos al tamaño de entrada y normalizamos como ImageNet \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "\n",
    "    # Oclusiones parciales para robustez ante muelles, niebla, etc. \n",
    "    transforms.RandomErasing(\n",
    "        p=0.2,\n",
    "        scale=(0.02, 0.15),\n",
    "        ratio=(0.3, 3.3)\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab2ccc8",
   "metadata": {},
   "source": [
    "## Preparación de datos\n",
    "\n",
    "- **Datasets**  \n",
    "  - `ShipsDs` / `ShipsDs_aug`: imágenes de barcos con transforms base y augmentadas.  \n",
    "  - `DockDs` / `DockDs_aug`: lo mismo para barcos atracados.\n",
    "\n",
    "- **Split**  \n",
    "  - Test: 20 %, Train: 80 %.  \n",
    "  - Semilla fija (`torch.manual_seed(42)`) para reproducibilidad.\n",
    "\n",
    "- **Particiones**  \n",
    "  - `random_split` en train/test para ambos datasets (con y sin augment).\n",
    "\n",
    "- **DataLoaders**  \n",
    "  - Batch size = 64.  \n",
    "  - Shuffle en train, no shuffle en test.  \n",
    "  - Cargadores por separado para versiones augmentadas y no augmentadas.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3cf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datasets \n",
    "ShipsDs = DatasetReader(\"materiales/ship.csv\", \"materiales/images\", transform= regnettransforms)\n",
    "ShipsDs_aug = DatasetReader(\"materiales/ship.csv\", \"materiales/images\", transform= aug_transforms)\n",
    "\n",
    "DockDs = DatasetReader(\"materiales/docked.csv\", \"materiales/images\", transform= regnettransforms)\n",
    "DockDs_aug = DatasetReader(\"materiales/docked.csv\", \"materiales/images\", transform= aug_transforms)\n",
    "\n",
    "TEST_RATIO = 0.2\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "num_train = int((1.0 - TEST_RATIO) * len(ShipsDs))\n",
    "num_test = len(ShipsDs) - num_train\n",
    "\n",
    "dc_num_train = int((1.0 - TEST_RATIO) * len(DockDs))\n",
    "dc_num_test = len(DockDs) - dc_num_train\n",
    "\n",
    "# Partitions\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(ShipsDs, [num_train, num_test])\n",
    "train_set_aug, _ = torch.utils.data.random_split(ShipsDs_aug, [num_train, num_test])\n",
    "\n",
    "# For docked dataset\n",
    "dc_train_set, dc_test_set = torch.utils.data.random_split(DockDs, [dc_num_train, dc_num_test])\n",
    "dc_train_set_aug, _ = torch.utils.data.random_split(DockDs_aug, [dc_num_train, dc_num_test])\n",
    "\n",
    "# Loaders for Ships\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False)\n",
    "\n",
    "train_loader_aug = torch.utils.data.DataLoader(train_set_aug, batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True)\n",
    "\n",
    "# Loaders for docks\n",
    "dc_train_loader = torch.utils.data.DataLoader(dc_train_set, batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True)\n",
    "dc_test_loader = torch.utils.data.DataLoader(dc_test_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False)\n",
    "\n",
    "dc_train_loader_aug = torch.utils.data.DataLoader(dc_train_set_aug, batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c04dd",
   "metadata": {},
   "source": [
    "## Definición de modelos\n",
    "\n",
    "- **Función `make_regnet(pretrained)`**  \n",
    "  - Carga `regnet_y_400mf` con o sin pesos (`pretrained=True/False`).  \n",
    "  - Reemplaza la capa final con un clasificador de 3 capas:  →256 →128 →2.\n",
    "\n",
    "- **Variantes por tarea**  \n",
    "  - **Ship / No Ship**:  \n",
    "    - `ship_scratch_noaug`, `ship_scratch_aug` (sin pesos).  \n",
    "    - `ship_pretrained_noaug`, `ship_pretrained_aug` (con pesos).  \n",
    "  - **Docked / Undocked**:  \n",
    "    - `dock_scratch_noaug`, `dock_scratch_aug` (sin pesos).  \n",
    "    - `dock_pretrained_noaug`, `dock_pretrained_aug` (con pesos).\n",
    "\n",
    "- **Agrupación**  \n",
    "  - Listas `ship_models` y `dock_models` para iterar fácilmente.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34131368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guill\\Desktop\\universidad\\tercero\\VCA\\practicas\\vca\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\guill\\Desktop\\universidad\\tercero\\VCA\\practicas\\vca\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\guill\\Desktop\\universidad\\tercero\\VCA\\practicas\\vca\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RegNet_Y_400MF_Weights.IMAGENET1K_V1`. You can also use `weights=RegNet_Y_400MF_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Función para crear y cambiar el final de una RegNet\n",
    "def make_regnet(pretrained: bool):\n",
    "    # pretrained=False  no carga pesos, True: carga los pesos\n",
    "    model = models.regnet_y_400mf(pretrained=pretrained)\n",
    "    in_feats = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(in_feats, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 2)      # salida binaria\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Creamos nuestros 4 “tipos” de modelo para cada tarea\n",
    "# Scratch: sin pesos\n",
    "# Pretrained: con pesos\n",
    "# aug: con data augmentation\n",
    "# noaug: sin data augmentation\n",
    "\n",
    "# Ship / No‑Ship\n",
    "ship_scratch_noaug    = make_regnet(pretrained=False)\n",
    "ship_scratch_aug      = make_regnet(pretrained=False)\n",
    "ship_pretrained_noaug = make_regnet(pretrained=True)\n",
    "ship_pretrained_aug   = make_regnet(pretrained=True)\n",
    "\n",
    "# Docked / Undocked\n",
    "dock_scratch_noaug    = make_regnet(pretrained=False)\n",
    "dock_scratch_aug      = make_regnet(pretrained=False)\n",
    "dock_pretrained_noaug = make_regnet(pretrained=True)\n",
    "dock_pretrained_aug   = make_regnet(pretrained=True)\n",
    "\n",
    "# Agrupamos en listas para iterar fácilmente\n",
    "ship_models = [\n",
    "    ship_scratch_noaug,\n",
    "    ship_scratch_aug,\n",
    "    ship_pretrained_noaug,\n",
    "    ship_pretrained_aug\n",
    "]\n",
    "dock_models = [\n",
    "    dock_scratch_noaug,\n",
    "    dock_scratch_aug,\n",
    "    dock_pretrained_noaug,\n",
    "    dock_pretrained_aug\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575c9fe",
   "metadata": {},
   "source": [
    "## Bucle de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "983c9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(model, train_loader, num_epochs, model_name=\"model\", lr=1e-4):\n",
    "    \"\"\"\n",
    "    Entrena durante num_epochs y guarda el modelo al final.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss, running_acc = 0.0, 0.0\n",
    "\n",
    "        for samples, targets in train_loader:\n",
    "            samples, targets = samples.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(samples)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_acc  += (outputs.argmax(1) == targets).float().mean().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc  = running_acc  / len(train_loader)\n",
    "        print(f\"[Train] Epoch {epoch}/{num_epochs} — Loss: {train_loss:.4f}, Acc: {train_acc*100:.2f}%\")\n",
    "\n",
    "    # Al terminar todas las épocas, guardamos el modelo\n",
    "    save_path = f\"{model_name}.pth\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Modelo final guardado en {save_path}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71fe968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, model_name=\"model\"):\n",
    "    #  Cargamos el modelo\n",
    "    checkpoint = torch.load(f\"{model_name}.pth\", map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    # Evaluamos\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss    = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for samples, targets in test_loader:\n",
    "            samples, targets = samples.to(device), targets.to(device)\n",
    "            outputs = model(samples)\n",
    "            total_loss    += criterion(outputs, targets).item()\n",
    "            preds          = outputs.argmax(dim=1)\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_acc  = total_correct / total_samples\n",
    "\n",
    "    print(f\"[Test] Loss: {avg_loss:.4f}, Acc: {avg_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79c44726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de los entrenamientos\n",
    "NUM_EPOCHS = 10\n",
    "LR         = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9681ed5",
   "metadata": {},
   "source": [
    "## Modelos sobre detección de barcos o su ausencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b737f48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Modelo sin pesos y sin data augmentation\n",
      "[Train] Epoch 1/10 — Loss: 0.6703, Acc: 61.02%\n",
      "[Train] Epoch 2/10 — Loss: 0.6395, Acc: 61.78%\n",
      "[Train] Epoch 3/10 — Loss: 0.6256, Acc: 61.40%\n",
      "[Train] Epoch 4/10 — Loss: 0.6022, Acc: 63.54%\n",
      "[Train] Epoch 5/10 — Loss: 0.5653, Acc: 66.27%\n",
      "[Train] Epoch 6/10 — Loss: 0.5250, Acc: 71.16%\n",
      "[Train] Epoch 7/10 — Loss: 0.4643, Acc: 81.29%\n",
      "[Train] Epoch 8/10 — Loss: 0.3919, Acc: 88.29%\n",
      "[Train] Epoch 9/10 — Loss: 0.3309, Acc: 90.85%\n",
      "[Train] Epoch 10/10 — Loss: 0.2501, Acc: 93.18%\n",
      "Modelo final guardado en ship_scratch_noaug.pth\n",
      "[Test] Loss: 0.9741, Acc: 32.20%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Modelo sin pesos y sin data augmentation\")\n",
    "train(ship_scratch_noaug, train_loader,      NUM_EPOCHS, model_name=\"ship_scratch_noaug\", lr=LR)\n",
    "test_model   (ship_scratch_noaug, test_loader,       model_name=\"ship_scratch_noaug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "981a576b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Modelo sin pesos y con data augmentation\n",
      "\n",
      "[Train] Epoch 1/10 — Loss: 0.6599, Acc: 63.54%\n",
      "[Train] Epoch 2/10 — Loss: 0.6607, Acc: 63.54%\n",
      "[Train] Epoch 3/10 — Loss: 0.6509, Acc: 63.93%\n",
      "[Train] Epoch 4/10 — Loss: 0.6546, Acc: 63.16%\n",
      "[Train] Epoch 5/10 — Loss: 0.6587, Acc: 63.74%\n",
      "[Train] Epoch 6/10 — Loss: 0.6545, Acc: 63.94%\n",
      "[Train] Epoch 7/10 — Loss: 0.6523, Acc: 64.12%\n",
      "[Train] Epoch 8/10 — Loss: 0.6601, Acc: 62.97%\n",
      "[Train] Epoch 9/10 — Loss: 0.6464, Acc: 63.74%\n",
      "[Train] Epoch 10/10 — Loss: 0.6545, Acc: 62.97%\n",
      "Modelo final guardado en ship_scratch_aug.pth\n",
      "[Test] Loss: 0.6320, Acc: 67.80%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Modelo sin pesos y con data augmentation\\n\")\n",
    "train(ship_scratch_aug,   train_loader_aug,  NUM_EPOCHS, model_name=\"ship_scratch_aug\",   lr=LR)\n",
    "test_model   (ship_scratch_aug,    test_loader,       model_name=\"ship_scratch_aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7719bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Modelo con pesos y sin data augmentation\n",
      "\n",
      "[Train] Epoch 1/10 — Loss: 0.6551, Acc: 74.42%\n",
      "[Train] Epoch 2/10 — Loss: 0.5421, Acc: 97.66%\n",
      "[Train] Epoch 3/10 — Loss: 0.4493, Acc: 97.67%\n",
      "[Train] Epoch 4/10 — Loss: 0.3468, Acc: 98.83%\n",
      "[Train] Epoch 5/10 — Loss: 0.2584, Acc: 99.22%\n",
      "[Train] Epoch 6/10 — Loss: 0.1785, Acc: 100.00%\n",
      "[Train] Epoch 7/10 — Loss: 0.1096, Acc: 100.00%\n",
      "[Train] Epoch 8/10 — Loss: 0.0633, Acc: 100.00%\n",
      "[Train] Epoch 9/10 — Loss: 0.0404, Acc: 100.00%\n",
      "[Train] Epoch 10/10 — Loss: 0.0230, Acc: 100.00%\n",
      "Modelo final guardado en ship_pretrained_noaug.pth\n",
      "[Test] Loss: 0.1580, Acc: 94.92%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Modelo con pesos y sin data augmentation\\n\")\n",
    "train(ship_pretrained_noaug, train_loader,   NUM_EPOCHS, model_name=\"ship_pretrained_noaug\", lr=LR)\n",
    "test_model   (ship_pretrained_noaug, test_loader,    model_name=\"ship_pretrained_noaug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32ac10b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Modelo con pesos y con data augmentation\n",
      "\n",
      "[Train] Epoch 1/10 — Loss: 0.6556, Acc: 63.74%\n",
      "[Train] Epoch 2/10 — Loss: 0.5835, Acc: 63.55%\n",
      "[Train] Epoch 3/10 — Loss: 0.5403, Acc: 63.57%\n",
      "[Train] Epoch 4/10 — Loss: 0.4568, Acc: 73.85%\n",
      "[Train] Epoch 5/10 — Loss: 0.3798, Acc: 88.09%\n",
      "[Train] Epoch 6/10 — Loss: 0.3179, Acc: 93.37%\n",
      "[Train] Epoch 7/10 — Loss: 0.2591, Acc: 96.29%\n",
      "[Train] Epoch 8/10 — Loss: 0.2023, Acc: 96.49%\n",
      "[Train] Epoch 9/10 — Loss: 0.1541, Acc: 96.68%\n",
      "[Train] Epoch 10/10 — Loss: 0.1293, Acc: 97.08%\n",
      "Modelo final guardado en ship_pretrained_aug.pth\n",
      "[Test] Loss: 0.1180, Acc: 96.61%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Modelo con pesos y con data augmentation\\n\")\n",
    "train(ship_pretrained_aug,   train_loader_aug, NUM_EPOCHS, model_name=\"ship_pretrained_aug\",   lr=LR)\n",
    "test_model   (ship_pretrained_aug,    test_loader,      model_name=\"ship_pretrained_aug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daca2b7d",
   "metadata": {},
   "source": [
    "## Modelos sobre detección de barcos atracados o navegando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22685618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Modelo sin pesos y sin data augmentation\n",
      "\n",
      "[Train] Epoch 1/10 — Loss: 0.6948, Acc: 56.33%\n",
      "[Train] Epoch 2/10 — Loss: 0.6794, Acc: 57.98%\n",
      "[Train] Epoch 3/10 — Loss: 0.6653, Acc: 63.29%\n",
      "[Train] Epoch 4/10 — Loss: 0.6722, Acc: 60.77%\n",
      "[Train] Epoch 5/10 — Loss: 0.6402, Acc: 65.19%\n",
      "[Train] Epoch 6/10 — Loss: 0.6222, Acc: 67.79%\n",
      "[Train] Epoch 7/10 — Loss: 0.6222, Acc: 68.12%\n",
      "[Train] Epoch 8/10 — Loss: 0.6016, Acc: 70.20%\n",
      "[Train] Epoch 9/10 — Loss: 0.5664, Acc: 74.04%\n",
      "[Train] Epoch 10/10 — Loss: 0.5658, Acc: 73.66%\n",
      "Modelo final guardado en dock_scratch_noaug.pth\n",
      "[Test] Loss: 0.8246, Acc: 43.24%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Modelo sin pesos y sin data augmentation\\n\")\n",
    "train(dock_scratch_noaug,    dc_train_loader,     NUM_EPOCHS, model_name=\"dock_scratch_noaug\",    lr=LR)\n",
    "test_model   (dock_scratch_noaug,    dc_test_loader,      model_name=\"dock_scratch_noaug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a364340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Modelo sin pesos y con data augmentation\n",
      "\n",
      "[Train] Epoch 1/10 — Loss: 0.6958, Acc: 48.27%\n",
      "[Train] Epoch 2/10 — Loss: 0.6933, Acc: 51.92%\n",
      "[Train] Epoch 3/10 — Loss: 0.6893, Acc: 53.34%\n",
      "[Train] Epoch 4/10 — Loss: 0.7022, Acc: 52.77%\n",
      "[Train] Epoch 5/10 — Loss: 0.6907, Acc: 54.91%\n",
      "[Train] Epoch 6/10 — Loss: 0.6916, Acc: 52.44%\n",
      "[Train] Epoch 7/10 — Loss: 0.6901, Acc: 51.21%\n",
      "[Train] Epoch 8/10 — Loss: 0.6738, Acc: 58.03%\n",
      "[Train] Epoch 9/10 — Loss: 0.6974, Acc: 57.84%\n",
      "[Train] Epoch 10/10 — Loss: 0.7127, Acc: 45.04%\n",
      "Modelo final guardado en dock_scratch_aug.pth\n",
      "[Test] Loss: 0.6953, Acc: 43.24%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Modelo sin pesos y con data augmentation\\n\")\n",
    "train(dock_scratch_aug,      dc_train_loader_aug, NUM_EPOCHS, model_name=\"dock_scratch_aug\",      lr=LR)\n",
    "test_model   (dock_scratch_aug,       dc_test_loader,      model_name=\"dock_scratch_aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1e9e1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Modelo con pesos y sin data augmentation\n",
      "\n",
      "[Train] Epoch 1/10 — Loss: 0.6874, Acc: 55.24%\n",
      "[Train] Epoch 2/10 — Loss: 0.6116, Acc: 85.36%\n",
      "[Train] Epoch 3/10 — Loss: 0.5448, Acc: 94.79%\n",
      "[Train] Epoch 4/10 — Loss: 0.4962, Acc: 90.05%\n",
      "[Train] Epoch 5/10 — Loss: 0.4235, Acc: 93.04%\n",
      "[Train] Epoch 6/10 — Loss: 0.3731, Acc: 92.32%\n",
      "[Train] Epoch 7/10 — Loss: 0.3243, Acc: 92.13%\n",
      "[Train] Epoch 8/10 — Loss: 0.2505, Acc: 95.64%\n",
      "[Train] Epoch 9/10 — Loss: 0.2008, Acc: 97.20%\n",
      "[Train] Epoch 10/10 — Loss: 0.1593, Acc: 100.00%\n",
      "Modelo final guardado en dock_pretrained_noaug.pth\n",
      "[Test] Loss: 0.2833, Acc: 91.89%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Modelo con pesos y sin data augmentation\\n\")\n",
    "train(dock_pretrained_noaug, dc_train_loader,     NUM_EPOCHS, model_name=\"dock_pretrained_noaug\", lr=LR)\n",
    "test_model   (dock_pretrained_noaug, dc_test_loader,      model_name=\"dock_pretrained_noaug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a94eb52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Modelo con pesos y con data augmentation\n",
      "\n",
      "[Train] Epoch 1/10 — Loss: 0.6985, Acc: 44.76%\n",
      "[Train] Epoch 2/10 — Loss: 0.6727, Acc: 67.27%\n",
      "[Train] Epoch 3/10 — Loss: 0.6559, Acc: 75.27%\n",
      "[Train] Epoch 4/10 — Loss: 0.6620, Acc: 66.89%\n",
      "[Train] Epoch 5/10 — Loss: 0.6342, Acc: 74.04%\n",
      "[Train] Epoch 6/10 — Loss: 0.6314, Acc: 72.42%\n",
      "[Train] Epoch 7/10 — Loss: 0.5917, Acc: 76.84%\n",
      "[Train] Epoch 8/10 — Loss: 0.5708, Acc: 80.48%\n",
      "[Train] Epoch 9/10 — Loss: 0.5591, Acc: 79.96%\n",
      "[Train] Epoch 10/10 — Loss: 0.5305, Acc: 79.44%\n",
      "Modelo final guardado en dock_pretrained_aug.pth\n",
      "[Test] Loss: 0.4517, Acc: 83.78%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Modelo con pesos y con data augmentation\\n\")\n",
    "train(dock_pretrained_aug,   dc_train_loader_aug, NUM_EPOCHS, model_name=\"dock_pretrained_aug\",   lr=LR)\n",
    "test_model   (dock_pretrained_aug,    dc_test_loader,      model_name=\"dock_pretrained_aug\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
